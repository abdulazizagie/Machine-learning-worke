{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json('https://api.exchangerate-api.com/v4/latest/INR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(host='localhost',user='root',password='',database='world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depend on you are you selecl the any table  only table name\n",
    "df = pd.read_sql_query(\"SELECT * FROM city WHERE CountryCode LIKE 'USA'\",conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "webpage=requests.get('https://t-one-youtube-converter.p.rapidapi.com/api/v1/infoVideo/?rapidapi-key=b161de8defmsh2792a311c1549b5p114bd0jsn9f1863ec76a0').text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in soup.find_all('h2'):\n",
    "  print(i.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all('p',class_='rating'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup.find_all('a' , class_='review-count'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company=soup.find_all('div',class_='company-content-wrapper')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(company) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "rating=[]\n",
    "reviews=[]\n",
    "ctype=[]\n",
    "hq=[]\n",
    "how_old=[]\n",
    "no_of_employee=[]\n",
    "\n",
    "for i in company:\n",
    "\n",
    "  name.append(i.find('h2').text.strip())\n",
    "  rating.append(i.find('p',class_='rating').text.strip())\n",
    "  reviews.append(i.find('a' , class_='review-count').text.strip())\n",
    "  ctype.append(i.find_all('p',class_='infoEntity')[0].text.strip())\n",
    "  hq.append(i.find_all('p',class_='infoEntity')[1].text.strip())\n",
    "  how_old.append(i.find_all('p',class_='infoEntity')[2].text.strip())\n",
    "  no_of_employee.append(i.find_all('p',class_='infoEntity')[3].text.strip())\n",
    "\n",
    "df=pd.DataFrame({'name':name,\n",
    "   'rating':rating,\n",
    "   'reviews':reviews,\n",
    "   'company_type':ctype,\n",
    "   'Head_Quarters':hq,\n",
    "   'Company_Age':how_old,\n",
    "   'No_of_Employee':no_of_employee,\n",
    "   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.DataFrame()\n",
    "for j in range(1,1001):\n",
    "  webpage=requests.get('https://www.ambitionbox.com/list-of-companies?page={}'.format(j)).text\n",
    "  soup=BeautifulSoup(webpage)\n",
    "  company=soup.find_all('div',class_='company-content-wrapper')\n",
    "  name=[]\n",
    "  rating=[]\n",
    "  reviews=[]\n",
    "  ctype=[]\n",
    "  hq=[]\n",
    "  how_old=[]\n",
    "  no_of_employee=[]\n",
    "\n",
    "  for i in company:\n",
    "\n",
    "    try:\n",
    "       name.append(i.find('h2').text.strip())\n",
    "    except:\n",
    "       name.append(np.nan)\n",
    "\n",
    "    try:\n",
    "       rating.append(i.find('p',class_='rating').text.strip())\n",
    "    except:\n",
    "       rating.append(np.nan)\n",
    "   \n",
    "    try:\n",
    "\n",
    "      reviews.append(i.find('a' , class_='review-count').text.strip())\n",
    "    except:\n",
    "      reviews.append(np.nan)\n",
    "\n",
    "    try:\n",
    "\n",
    "      ctype.append(i.find_all('p',class_='infoEntity')[0].text.strip())\n",
    "    except:\n",
    "      ctype.append(np.nan)\n",
    "    try:\n",
    "\n",
    "      hq.append(i.find_all('p',class_='infoEntity')[1].text.strip())\n",
    "    except:\n",
    "      hq.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "\n",
    "      how_old.append(i.find_all('p',class_='infoEntity')[2].text.strip())\n",
    "    except:\n",
    "      how_old.append(np.nan)\n",
    "    try:\n",
    "      no_of_employee.append(i.find_all('p',class_='infoEntity')[3].text.strip())\n",
    "    except:\n",
    "      no_of_employee.append(np.nan)\n",
    "    \n",
    "\n",
    "  df=pd.DataFrame({'name':name,\n",
    "    'rating':rating,\n",
    "    'reviews':reviews,\n",
    "    'company_type':ctype,\n",
    "    'Head_Quarters':hq,\n",
    "    'Company_Age':how_old,\n",
    "    'No_of_Employee':no_of_employee,\n",
    "    })\n",
    "  \n",
    "  # final=final.append(df,ignore_index=True)\n",
    "  final = pd.concat([df],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e18d32e78a9d1f6b5d41bcc9620a33cb0eb8a83172e9526f1e29732f1c151e0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
